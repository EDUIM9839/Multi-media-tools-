<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Image to Video with TTS and Audio Embed</title>
  <style>
    body {
      font-family: sans-serif;
      padding: 20px;
      max-width: 800px;
      margin: auto;
    }
    input, button {
      font-size: 16px;
      padding: 10px;
      margin: 10px 0;
      width: 100%;
      box-sizing: border-box;
    }
    #previewImage {
      max-width: 100%;
      margin-bottom: 10px;
    }
    video {
      width: 100%;
      max-width: 640px;
      margin-top: 20px;
    }
    #stepSection {
      display: none;
    }
  </style>
</head>
<body>
  <h1>Upload Images, Add Text & Duration</h1>

  <input type="file" id="imageUpload" accept="image/*" multiple />
  <div id="stepSection">
    <img id="previewImage" src="" alt="Preview" />
    <input type="text" id="imageText" placeholder="Enter text for this image" />
    <input type="number" id="imageDuration" placeholder="Duration (seconds)" value="3" min="1" />
    <button id="nextBtn">Next</button>
  </div>

  <button id="generateBtn" style="display:none;">Generate Video</button>
  <p id="totalDuration" style="font-weight: bold;"></p>
  <video id="outputVideo" controls></video>
  <button id="downloadBtn" style="display:none;">Download Video</button>
  <canvas id="canvas" width="640" height="480" style="display:none;"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@latest"></script>
  <script>
    const imageUpload = document.getElementById('imageUpload');
    const stepSection = document.getElementById('stepSection');
    const previewImage = document.getElementById('previewImage');
    const imageText = document.getElementById('imageText');
    const imageDuration = document.getElementById('imageDuration');
    const nextBtn = document.getElementById('nextBtn');
    const generateBtn = document.getElementById('generateBtn');
    const totalDurationEl = document.getElementById('totalDuration');
    const downloadBtn = document.getElementById('downloadBtn');
    const outputVideo = document.getElementById('outputVideo');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    let files = [];
    let currentIndex = 0;
    let imageData = [];

    imageUpload.onchange = () => {
      files = Array.from(imageUpload.files);
      currentIndex = 0;
      imageData = [];

      if (files.length > 0) {
        loadImageStep(currentIndex);
      }
    };

    function loadImageStep(index) {
      const file = files[index];
      const url = URL.createObjectURL(file);
      previewImage.src = url;
      imageText.value = '';
      imageDuration.value = 3;
      stepSection.style.display = 'block';
    }

    nextBtn.onclick = () => {
      const file = files[currentIndex];
      const text = imageText.value.trim();
      const duration = parseInt(imageDuration.value) || 3;
      imageData.push({ file, text, duration });

      currentIndex++;
      if (currentIndex < files.length) {
        loadImageStep(currentIndex);
      } else {
        stepSection.style.display = 'none';
        generateBtn.style.display = 'block';
      }
    };

    async function generateAudioBlob(text) {
      return new Promise((resolve, reject) => {
        const synth = window.speechSynthesis;
        const utterance = new SpeechSynthesisUtterance(text);
        const audioContext = new AudioContext();
        const dest = audioContext.createMediaStreamDestination();

        const source = audioContext.createMediaStreamSource(dest.stream);
        const recorder = new MediaRecorder(dest.stream);
        const chunks = [];

        recorder.ondataavailable = e => chunks.push(e.data);
        recorder.onstop = () => {
          const blob = new Blob(chunks, { type: 'audio/wav' });
          resolve(blob);
        };

        utterance.onstart = () => {
          recorder.start();
        };

        utterance.onend = () => {
          recorder.stop();
          audioContext.close();
        };

        synth.speak(utterance);
      });
    }

    async function createVideoWithAudio(images, audioBlob) {
      const { createFFmpeg, fetchFile } = FFmpeg;
      const ffmpeg = createFFmpeg({ log: true });
      await ffmpeg.load();

      images.forEach((image, index) => {
        ffmpeg.FS('writeFile', `image${index}.jpg`, new Uint8Array(await image.arrayBuffer()));
      });

      const audioArrayBuffer = await audioBlob.arrayBuffer();
      ffmpeg.FS('writeFile', 'audio.wav', new Uint8Array(audioArrayBuffer));

      await ffmpeg.run(
        '-framerate', '1',
        '-i', 'image%d.jpg',
        '-i', 'audio.wav',
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-strict', 'experimental',
        '-shortest',
        'output.mp4'
      );

      const data = ffmpeg.FS('readFile', 'output.mp4');
      const videoBlob = new Blob([data.buffer], { type: 'video/mp4' });
      const videoUrl = URL.createObjectURL(videoBlob);

      return videoUrl;
    }

    generateBtn.onclick = async () => {
      generateBtn.disabled = true;
      const totalDuration = imageData.reduce((sum, img) => sum + img.duration, 0);
      totalDurationEl.textContent = `Total Video Duration: ${totalDuration} seconds`;

      const images = [];
      for (const { file, text, duration } of imageData) {
        const img = new Image();
        img.src = URL.createObjectURL(file);
        await img.decode();

        const audioBlob = await generateAudioBlob(text);

        images.push(img);
      }

      const videoUrl = await createVideoWithAudio(images, audioBlob);
      outputVideo.src = videoUrl;

      downloadBtn.style.display = 'inline-block';
      downloadBtn.onclick = () => {
        const a = document.createElement('a');
        a.href = videoUrl;
        a.download = 'output.mp4';
        a.click();
      };


::contentReference[oaicite:10]{index=10}
